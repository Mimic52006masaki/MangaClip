{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 262, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/scraper.ts"],"sourcesContent":["import axios from 'axios';\nimport * as cheerio from 'cheerio';\n\nexport interface ScrapedArticle {\n  title: string;\n  url: string;\n}\n\n// Manga summary news\nexport async function scrapeMangaArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?key=%e6%bc%ab%e7%94%bb%e3%81%be%e3%81%a8%e3%82%81%e9%80%9f%e5%a0%b1';\n\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.startsWith('./cnt.cgi?')) {\n            const urlA = href.split('=')[1];\n            if (urlA) fullUrl = urlA;\n          } else if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    // Deduplicate by URL\n    const uniqueArticles = articles.filter((article, index, self) =>\n      index === self.findIndex(a => a.url === article.url)\n    );\n\n    return uniqueArticles;\n  } catch (error) {\n    console.error('Error scraping manga articles:', error);\n    throw new Error('Failed to scrape manga articles');\n  }\n}\n\n// Anime summary\nexport async function scrapeAnimeArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?c_10=1&c_11=1&c_15=1&c_16=1&c_17=1&c_20=1&c_24=1&c_30=1&c_31=1&c_40=1&c_41=1&c_45=1&c_51=1&c_60=1&c_61=1&c_63=1&c_70=1&c_95=1&c_99=1&type=month&key=%E3%82%A2%E3%83%8B%E3%83%A1%E3%81%BE%E3%81%A8%E3%82%81&btn=%E3%81%8A&chkb=1';\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.startsWith('./cnt.cgi?')) {\n            const urlA = href.split('=')[1];\n            if (urlA) fullUrl = urlA;\n          } else if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    // Deduplicate by URL\n    const uniqueArticles = articles.filter((article, index, self) =>\n      index === self.findIndex(a => a.url === article.url)\n    );\n\n    return uniqueArticles;\n  } catch (error) {\n    console.error('Error scraping anime articles:', error);\n    throw new Error('Failed to scrape anime articles');\n  }\n}\n\n// Scrape articles from a specific URL\nexport async function scrapeArticlesFromUrl(siteType: 'manga' | 'anime', url: string, filterUrl?: string): Promise<ScrapedArticle[]> {\n  try {\n    const response = await axios.get(url, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Try multiple selectors for titles\n    const selectors = [\n      'table.table01 tr:has(hr) td.title',\n      'h1', 'h2', 'h3',\n      '.title', '.article-title',\n      'title'\n    ];\n\n    // First try the original method for anaguro.yanen.org\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.startsWith('./cnt.cgi?')) {\n            const urlA = href.split('=')[1];\n            if (urlA) fullUrl = urlA;\n          } else if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    // If no articles found, try general selectors\n    if (articles.length === 0) {\n      const generalSelectors = ['h1', 'h2', 'h3', '.title', '.article-title'];\n      generalSelectors.forEach(selector => {\n        $(selector).each((_, elem) => {\n          const title = $(elem).text().trim();\n          if (title) {\n            const link = $(elem).find('a').attr('href') || $(elem).closest('a').attr('href') || url;\n            let fullUrl = link;\n            if (fullUrl.startsWith('./cnt.cgi?')) {\n              const urlA = fullUrl.split('=')[1];\n              if (urlA) fullUrl = urlA;\n            } else if (fullUrl.includes('anaguro.yanen.org/')) {\n              fullUrl = fullUrl.replace('https://anaguro.yanen.org/', '');\n            }\n            articles.push({ title, url: fullUrl.trim() });\n          }\n        });\n      });\n\n      // Deduplicate\n      const uniqueArticles = articles.filter((article, index, self) =>\n        index === self.findIndex(a => a.url === article.url)\n      );\n      articles.splice(0, articles.length, ...uniqueArticles);\n    }\n\n    // Fallback: use page title if no articles found\n    if (articles.length === 0) {\n      const pageTitle = $('title').text().trim();\n      if (pageTitle) {\n        articles.push({ title: pageTitle, url: url });\n      }\n    }\n\n    return articles;\n  } catch (error) {\n    console.error('Error scraping articles from URL:', error);\n    throw new Error('Failed to scrape articles from URL');\n  }\n}"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AAAA;;;AAQO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAElB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,UAAU,CAAC,eAAe;wBACjC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC/B,IAAI,MAAM,UAAU;oBACtB,OAAO,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBAC9C,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,qBAAqB;QACrB,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,SAAS,OAAO,OACtD,UAAU,KAAK,SAAS,CAAC,CAAA,IAAK,EAAE,GAAG,KAAK,QAAQ,GAAG;QAGrD,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF;AAGO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAClB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,UAAU,CAAC,eAAe;wBACjC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC/B,IAAI,MAAM,UAAU;oBACtB,OAAO,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBAC9C,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,qBAAqB;QACrB,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,SAAS,OAAO,OACtD,UAAU,KAAK,SAAS,CAAC,CAAA,IAAK,EAAE,GAAG,KAAK,QAAQ,GAAG;QAGrD,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF;AAGO,eAAe,sBAAsB,QAA2B,EAAE,GAAW,EAAE,SAAkB;IACtG,IAAI;QACF,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,KAAK;YACpC,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,oCAAoC;QACpC,MAAM,YAAY;YAChB;YACA;YAAM;YAAM;YACZ;YAAU;YACV;SACD;QAED,sDAAsD;QACtD,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,UAAU,CAAC,eAAe;wBACjC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC/B,IAAI,MAAM,UAAU;oBACtB,OAAO,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBAC9C,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,8CAA8C;QAC9C,IAAI,SAAS,MAAM,KAAK,GAAG;YACzB,MAAM,mBAAmB;gBAAC;gBAAM;gBAAM;gBAAM;gBAAU;aAAiB;YACvE,iBAAiB,OAAO,CAAC,CAAA;gBACvB,EAAE,UAAU,IAAI,CAAC,CAAC,GAAG;oBACnB,MAAM,QAAQ,EAAE,MAAM,IAAI,GAAG,IAAI;oBACjC,IAAI,OAAO;wBACT,MAAM,OAAO,EAAE,MAAM,IAAI,CAAC,KAAK,IAAI,CAAC,WAAW,EAAE,MAAM,OAAO,CAAC,KAAK,IAAI,CAAC,WAAW;wBACpF,IAAI,UAAU;wBACd,IAAI,QAAQ,UAAU,CAAC,eAAe;4BACpC,MAAM,OAAO,QAAQ,KAAK,CAAC,IAAI,CAAC,EAAE;4BAClC,IAAI,MAAM,UAAU;wBACtB,OAAO,IAAI,QAAQ,QAAQ,CAAC,uBAAuB;4BACjD,UAAU,QAAQ,OAAO,CAAC,8BAA8B;wBAC1D;wBACA,SAAS,IAAI,CAAC;4BAAE;4BAAO,KAAK,QAAQ,IAAI;wBAAG;oBAC7C;gBACF;YACF;YAEA,cAAc;YACd,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,SAAS,OAAO,OACtD,UAAU,KAAK,SAAS,CAAC,CAAA,IAAK,EAAE,GAAG,KAAK,QAAQ,GAAG;YAErD,SAAS,MAAM,CAAC,GAAG,SAAS,MAAM,KAAK;QACzC;QAEA,gDAAgD;QAChD,IAAI,SAAS,MAAM,KAAK,GAAG;YACzB,MAAM,YAAY,EAAE,SAAS,IAAI,GAAG,IAAI;YACxC,IAAI,WAAW;gBACb,SAAS,IAAI,CAAC;oBAAE,OAAO;oBAAW,KAAK;gBAAI;YAC7C;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,qCAAqC;QACnD,MAAM,IAAI,MAAM;IAClB;AACF"}},
    {"offset": {"line": 466, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/database.ts"],"sourcesContent":["import Database from 'better-sqlite3';\nimport path from 'path';\n\nconsole.log('Initializing database module');\n\n// Database path\nconst dbPath = path.join(process.cwd(), 'mangaclip.db');\nconsole.log('DB path:', dbPath);\nconst db = new Database(dbPath);\nconsole.log('DB instance created');\n\n// Enable WAL mode for better concurrency\ndb.pragma('journal_mode = WAL');\n\n// Create tables\nconsole.log('Creating tables...');\ndb.exec(`\n  CREATE TABLE IF NOT EXISTS manga_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    originalTitle TEXT NOT NULL,\n    generatedTitle TEXT,\n    url TEXT NOT NULL UNIQUE,\n    targetDate TEXT,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    checked BOOLEAN DEFAULT FALSE\n  );\n\n  CREATE TABLE IF NOT EXISTS anime_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    title TEXT NOT NULL,\n    url TEXT NOT NULL UNIQUE,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP\n  );\n\n  CREATE TABLE IF NOT EXISTS article_date_tags (\n    anchor_post_id INTEGER PRIMARY KEY,\n    date TEXT NOT NULL,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP\n  );\n`);\n\n// Add post_id column if not exists\ntry {\n  db.exec(`ALTER TABLE manga_articles ADD COLUMN post_id INTEGER;`);\n  console.log('Added post_id column');\n} catch (error: any) {\n  // Column might already exist, ignore error\n  console.log('post_id column already exists or error adding:', error?.message);\n}\n\n// Add unique index for post_id if not exists\ntry {\n  db.exec(`CREATE UNIQUE INDEX IF NOT EXISTS idx_manga_articles_post_id ON manga_articles(post_id);`);\n  console.log('Created post_id index');\n} catch (error: any) {\n  console.log('Index creation error:', error?.message);\n}\n\nconsole.log('Tables created successfully');\n\n// Populate existing data with post_id if not set\ntry {\n  const rows = db.prepare('SELECT id, url FROM manga_articles WHERE post_id IS NULL').all() as { id: number; url: string }[];\n  if (rows.length > 0) {\n    const update = db.prepare('UPDATE manga_articles SET post_id = ? WHERE id = ?');\n    for (const row of rows) {\n      const match = row.url.match(/\\/post\\/(\\d+)\\//);\n      if (match) {\n        update.run(Number(match[1]), row.id);\n      }\n    }\n    console.log(`Populated post_id for ${rows.length} existing rows`);\n  }\n} catch (error: any) {\n  console.log('Error populating post_id:', error?.message);\n}\n\n// Types\nexport interface MangaArticle {\n  id: number;\n  originalTitle: string;\n  generatedTitle: string | null;\n  url: string;\n  post_id: number;\n  targetDate: string | null;\n  createdAt: string;\n  updatedAt: string;\n  checked: boolean;\n}\n\nexport interface AnimeArticle {\n  id: number;\n  title: string;\n  url: string;\n  createdAt: string;\n  updatedAt: string;\n}\n\nexport interface ArticleDateTag {\n  anchor_post_id: number;\n  date: string;\n  createdAt: string;\n}\n\nexport default db;"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,QAAQ,GAAG,CAAC;AAEZ,gBAAgB;AAChB,MAAM,SAAS,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;AACxC,QAAQ,GAAG,CAAC,YAAY;AACxB,MAAM,KAAK,IAAI,qOAAQ,CAAC;AACxB,QAAQ,GAAG,CAAC;AAEZ,yCAAyC;AACzC,GAAG,MAAM,CAAC;AAEV,gBAAgB;AAChB,QAAQ,GAAG,CAAC;AACZ,GAAG,IAAI,CAAC,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;AAyBT,CAAC;AAED,mCAAmC;AACnC,IAAI;IACF,GAAG,IAAI,CAAC,CAAC,sDAAsD,CAAC;IAChE,QAAQ,GAAG,CAAC;AACd,EAAE,OAAO,OAAY;IACnB,2CAA2C;IAC3C,QAAQ,GAAG,CAAC,kDAAkD,OAAO;AACvE;AAEA,6CAA6C;AAC7C,IAAI;IACF,GAAG,IAAI,CAAC,CAAC,wFAAwF,CAAC;IAClG,QAAQ,GAAG,CAAC;AACd,EAAE,OAAO,OAAY;IACnB,QAAQ,GAAG,CAAC,yBAAyB,OAAO;AAC9C;AAEA,QAAQ,GAAG,CAAC;AAEZ,iDAAiD;AACjD,IAAI;IACF,MAAM,OAAO,GAAG,OAAO,CAAC,4DAA4D,GAAG;IACvF,IAAI,KAAK,MAAM,GAAG,GAAG;QACnB,MAAM,SAAS,GAAG,OAAO,CAAC;QAC1B,KAAK,MAAM,OAAO,KAAM;YACtB,MAAM,QAAQ,IAAI,GAAG,CAAC,KAAK,CAAC;YAC5B,IAAI,OAAO;gBACT,OAAO,GAAG,CAAC,OAAO,KAAK,CAAC,EAAE,GAAG,IAAI,EAAE;YACrC;QACF;QACA,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,KAAK,MAAM,CAAC,cAAc,CAAC;IAClE;AACF,EAAE,OAAO,OAAY;IACnB,QAAQ,GAAG,CAAC,6BAA6B,OAAO;AAClD;uCA6Be"}},
    {"offset": {"line": 547, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/app/api/scrape/anime/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { scrapeAnimeArticles } from '@/lib/scraper';\nimport db, { AnimeArticle } from '@/lib/database';\n\nexport async function POST() {\n  try {\n    // Scrape articles\n    const scrapedArticles = await scrapeAnimeArticles();\n\n    // Get existing URLs to check duplicates\n    const existingUrls = db.prepare('SELECT url FROM anime_articles').all() as { url: string }[];\n    const existingUrlSet = new Set(existingUrls.map(row => row.url));\n\n    // Filter out duplicates\n    const newArticles = scrapedArticles.filter(article => !existingUrlSet.has(article.url));\n\n    // Insert new articles\n    const insert = db.prepare(`\n      INSERT INTO anime_articles (title, url)\n      VALUES (?, ?)\n    `);\n\n    const insertedArticles: AnimeArticle[] = [];\n\n    for (const article of newArticles) {\n      const result = insert.run(article.title, article.url);\n      const insertedArticle = db.prepare('SELECT * FROM anime_articles WHERE id = ?').get(result.lastInsertRowid) as AnimeArticle;\n      insertedArticles.push(insertedArticle);\n    }\n\n    return NextResponse.json({\n      success: true,\n      scraped: scrapedArticles.length,\n      new: newArticles.length,\n      articles: insertedArticles\n    });\n  } catch (error) {\n    console.error('Error in anime scrape:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to scrape anime articles' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function GET() {\n  try {\n    const articles = db.prepare(`\n      SELECT * FROM anime_articles\n      ORDER BY createdAt DESC\n    `).all() as AnimeArticle[];\n\n    return NextResponse.json({ success: true, articles });\n  } catch (error) {\n    console.error('Error fetching anime articles:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to fetch articles' },\n      { status: 500 }\n    );\n  }\n}"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AAEO,eAAe;IACpB,IAAI;QACF,kBAAkB;QAClB,MAAM,kBAAkB,MAAM,IAAA,8KAAmB;QAEjD,wCAAwC;QACxC,MAAM,eAAe,mKAAE,CAAC,OAAO,CAAC,kCAAkC,GAAG;QACrE,MAAM,iBAAiB,IAAI,IAAI,aAAa,GAAG,CAAC,CAAA,MAAO,IAAI,GAAG;QAE9D,wBAAwB;QACxB,MAAM,cAAc,gBAAgB,MAAM,CAAC,CAAA,UAAW,CAAC,eAAe,GAAG,CAAC,QAAQ,GAAG;QAErF,sBAAsB;QACtB,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,CAAC;;;IAG3B,CAAC;QAED,MAAM,mBAAmC,EAAE;QAE3C,KAAK,MAAM,WAAW,YAAa;YACjC,MAAM,SAAS,OAAO,GAAG,CAAC,QAAQ,KAAK,EAAE,QAAQ,GAAG;YACpD,MAAM,kBAAkB,mKAAE,CAAC,OAAO,CAAC,6CAA6C,GAAG,CAAC,OAAO,eAAe;YAC1G,iBAAiB,IAAI,CAAC;QACxB;QAEA,OAAO,uLAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS,gBAAgB,MAAM;YAC/B,KAAK,YAAY,MAAM;YACvB,UAAU;QACZ;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAkC,GAC3D;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe;IACpB,IAAI;QACF,MAAM,WAAW,mKAAE,CAAC,OAAO,CAAC,CAAC;;;IAG7B,CAAC,EAAE,GAAG;QAEN,OAAO,uLAAY,CAAC,IAAI,CAAC;YAAE,SAAS;YAAM;QAAS;IACrD,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}