{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 262, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/scraper.ts"],"sourcesContent":["import axios from 'axios';\nimport * as cheerio from 'cheerio';\n\nexport interface ScrapedArticle {\n  title: string;\n  url: string;\n}\n\n// Manga summary news\nexport async function scrapeMangaArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?key=%e6%bc%ab%e7%94%bb%e3%81%be%e3%81%a8%e3%82%81%e9%80%9f%e5%a0%b1';\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          const urlA = href.replace('./cnt.cgi?1778=', '');\n          const fullUrl = 'https://anaguro.yanen.org/' + urlA;\n          articles.push({ title, url: fullUrl });\n        }\n      }\n    });\n\n    return articles;\n  } catch (error) {\n    console.error('Error scraping manga articles:', error);\n    throw new Error('Failed to scrape manga articles');\n  }\n}\n\n// Anime summary\nexport async function scrapeAnimeArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?c_10=1&c_11=1&c_15=1&c_16=1&c_17=1&c_20=1&c_24=1&c_30=1&c_31=1&c_40=1&c_41=1&c_45=1&c_51=1&c_60=1&c_61=1&c_63=1&c_70=1&c_95=1&c_99=1&type=month&key=%E3%82%A2%E3%83%8B%E3%83%A1%E3%81%BE%E3%81%A8%E3%82%81&btn=%E3%81%8A&chkb=1';\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          const urlA = href.replace('./cnt.cgi?1996=', '');\n          const fullUrl = 'https://anaguro.yanen.org/' + urlA;\n          articles.push({ title, url: fullUrl });\n        }\n      }\n    });\n\n    return articles;\n  } catch (error) {\n    console.error('Error scraping anime articles:', error);\n    throw new Error('Failed to scrape anime articles');\n  }\n}"],"names":[],"mappings":";;;;;;AAAA;AACA;AAAA;;;AAQO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAClB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,MAAM,OAAO,KAAK,OAAO,CAAC,mBAAmB;oBAC7C,MAAM,UAAU,+BAA+B;oBAC/C,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK;oBAAQ;gBACtC;YACF;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF;AAGO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAClB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,MAAM,OAAO,KAAK,OAAO,CAAC,mBAAmB;oBAC7C,MAAM,UAAU,+BAA+B;oBAC/C,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK;oBAAQ;gBACtC;YACF;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF"}},
    {"offset": {"line": 355, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/database.ts"],"sourcesContent":["import Database from 'better-sqlite3';\nimport path from 'path';\n\nconsole.log('Initializing database module');\n\n// Database path\nconst dbPath = path.join(process.cwd(), 'mangaclip.db');\nconsole.log('DB path:', dbPath);\nconst db = new Database(dbPath);\nconsole.log('DB instance created');\n\n// Enable WAL mode for better concurrency\ndb.pragma('journal_mode = WAL');\n\n// Create tables\nconsole.log('Creating tables...');\ndb.exec(`\n  CREATE TABLE IF NOT EXISTS manga_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    originalTitle TEXT NOT NULL,\n    generatedTitle TEXT,\n    url TEXT NOT NULL UNIQUE,\n    targetDate TEXT,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    checked BOOLEAN DEFAULT FALSE\n  );\n\n  CREATE TABLE IF NOT EXISTS anime_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    title TEXT NOT NULL,\n    url TEXT NOT NULL UNIQUE,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP\n  );\n`);\nconsole.log('Tables created successfully');\n\n// Types\nexport interface MangaArticle {\n  id: number;\n  originalTitle: string;\n  generatedTitle: string | null;\n  url: string;\n  targetDate: string | null;\n  createdAt: string;\n  updatedAt: string;\n  checked: boolean;\n}\n\nexport interface AnimeArticle {\n  id: number;\n  title: string;\n  url: string;\n  createdAt: string;\n  updatedAt: string;\n}\n\nexport default db;"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,QAAQ,GAAG,CAAC;AAEZ,gBAAgB;AAChB,MAAM,SAAS,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;AACxC,QAAQ,GAAG,CAAC,YAAY;AACxB,MAAM,KAAK,IAAI,qOAAQ,CAAC;AACxB,QAAQ,GAAG,CAAC;AAEZ,yCAAyC;AACzC,GAAG,MAAM,CAAC;AAEV,gBAAgB;AAChB,QAAQ,GAAG,CAAC;AACZ,GAAG,IAAI,CAAC,CAAC;;;;;;;;;;;;;;;;;;;AAmBT,CAAC;AACD,QAAQ,GAAG,CAAC;uCAsBG"}},
    {"offset": {"line": 399, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/app/api/scrape/anime/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { scrapeAnimeArticles } from '@/lib/scraper';\nimport db, { AnimeArticle } from '@/lib/database';\n\nexport async function POST() {\n  try {\n    // Scrape articles\n    const scrapedArticles = await scrapeAnimeArticles();\n\n    // Get existing URLs to check duplicates\n    const existingUrls = db.prepare('SELECT url FROM anime_articles').all() as { url: string }[];\n    const existingUrlSet = new Set(existingUrls.map(row => row.url));\n\n    // Filter out duplicates\n    const newArticles = scrapedArticles.filter(article => !existingUrlSet.has(article.url));\n\n    // Insert new articles\n    const insert = db.prepare(`\n      INSERT INTO anime_articles (title, url)\n      VALUES (?, ?)\n    `);\n\n    const insertedArticles: AnimeArticle[] = [];\n\n    for (const article of newArticles) {\n      const result = insert.run(article.title, article.url);\n      const insertedArticle = db.prepare('SELECT * FROM anime_articles WHERE id = ?').get(result.lastInsertRowid) as AnimeArticle;\n      insertedArticles.push(insertedArticle);\n    }\n\n    return NextResponse.json({\n      success: true,\n      scraped: scrapedArticles.length,\n      new: newArticles.length,\n      articles: insertedArticles\n    });\n  } catch (error) {\n    console.error('Error in anime scrape:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to scrape anime articles' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function GET() {\n  try {\n    const articles = db.prepare(`\n      SELECT * FROM anime_articles\n      ORDER BY createdAt DESC\n    `).all() as AnimeArticle[];\n\n    return NextResponse.json({ success: true, articles });\n  } catch (error) {\n    console.error('Error fetching anime articles:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to fetch articles' },\n      { status: 500 }\n    );\n  }\n}"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AAEO,eAAe;IACpB,IAAI;QACF,kBAAkB;QAClB,MAAM,kBAAkB,MAAM,IAAA,8KAAmB;QAEjD,wCAAwC;QACxC,MAAM,eAAe,mKAAE,CAAC,OAAO,CAAC,kCAAkC,GAAG;QACrE,MAAM,iBAAiB,IAAI,IAAI,aAAa,GAAG,CAAC,CAAA,MAAO,IAAI,GAAG;QAE9D,wBAAwB;QACxB,MAAM,cAAc,gBAAgB,MAAM,CAAC,CAAA,UAAW,CAAC,eAAe,GAAG,CAAC,QAAQ,GAAG;QAErF,sBAAsB;QACtB,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,CAAC;;;IAG3B,CAAC;QAED,MAAM,mBAAmC,EAAE;QAE3C,KAAK,MAAM,WAAW,YAAa;YACjC,MAAM,SAAS,OAAO,GAAG,CAAC,QAAQ,KAAK,EAAE,QAAQ,GAAG;YACpD,MAAM,kBAAkB,mKAAE,CAAC,OAAO,CAAC,6CAA6C,GAAG,CAAC,OAAO,eAAe;YAC1G,iBAAiB,IAAI,CAAC;QACxB;QAEA,OAAO,uLAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS,gBAAgB,MAAM;YAC/B,KAAK,YAAY,MAAM;YACvB,UAAU;QACZ;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAkC,GAC3D;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe;IACpB,IAAI;QACF,MAAM,WAAW,mKAAE,CAAC,OAAO,CAAC,CAAC;;;IAG7B,CAAC,EAAE,GAAG;QAEN,OAAO,uLAAY,CAAC,IAAI,CAAC;YAAE,SAAS;YAAM;QAAS;IACrD,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}