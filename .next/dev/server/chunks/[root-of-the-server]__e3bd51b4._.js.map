{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 262, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/scraper.ts"],"sourcesContent":["import axios from 'axios';\nimport * as cheerio from 'cheerio';\n\nexport interface ScrapedArticle {\n  title: string;\n  url: string;\n}\n\n// Manga summary news\nexport async function scrapeMangaArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?key=%e6%bc%ab%e7%94%bb%e3%81%be%e3%81%a8%e3%82%81%e9%80%9f%e5%a0%b1';\n\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.startsWith('./cnt.cgi?')) {\n            const urlA = href.split('=')[1];\n            if (urlA) fullUrl = urlA;\n          } else if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    // Deduplicate by URL\n    const uniqueArticles = articles.filter((article, index, self) =>\n      index === self.findIndex(a => a.url === article.url)\n    );\n\n    return uniqueArticles;\n  } catch (error) {\n    console.error('Error scraping manga articles:', error);\n    throw new Error('Failed to scrape manga articles');\n  }\n}\n\n// Anime summary\nexport async function scrapeAnimeArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?c_10=1&c_11=1&c_15=1&c_16=1&c_17=1&c_20=1&c_24=1&c_30=1&c_31=1&c_40=1&c_41=1&c_45=1&c_51=1&c_60=1&c_61=1&c_63=1&c_70=1&c_95=1&c_99=1&type=month&key=%E3%82%A2%E3%83%8B%E3%83%A1%E3%81%BE%E3%81%A8%E3%82%81&btn=%E3%81%8A&chkb=1';\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.startsWith('./cnt.cgi?')) {\n            const urlA = href.split('=')[1];\n            if (urlA) fullUrl = urlA;\n          } else if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    // Deduplicate by URL\n    const uniqueArticles = articles.filter((article, index, self) =>\n      index === self.findIndex(a => a.url === article.url)\n    );\n\n    return uniqueArticles;\n  } catch (error) {\n    console.error('Error scraping anime articles:', error);\n    throw new Error('Failed to scrape anime articles');\n  }\n}\n\n// Scrape articles from a specific URL\nexport async function scrapeArticlesFromUrl(siteType: 'manga' | 'anime', url: string, filterUrl?: string): Promise<ScrapedArticle[]> {\n  try {\n    const response = await axios.get(url, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Try multiple selectors for titles\n    const selectors = [\n      'table.table01 tr:has(hr) td.title',\n      'h1', 'h2', 'h3',\n      '.title', '.article-title',\n      'title'\n    ];\n\n    // First try the original method for anaguro.yanen.org\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.startsWith('./cnt.cgi?')) {\n            const urlA = href.split('=')[1];\n            if (urlA) fullUrl = urlA;\n          } else if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    // If no articles found, try general selectors\n    if (articles.length === 0) {\n      const generalSelectors = ['h1', 'h2', 'h3', '.title', '.article-title'];\n      generalSelectors.forEach(selector => {\n        $(selector).each((_, elem) => {\n          const title = $(elem).text().trim();\n          if (title) {\n            const link = $(elem).find('a').attr('href') || $(elem).closest('a').attr('href') || url;\n            let fullUrl = link;\n            if (fullUrl.startsWith('./cnt.cgi?')) {\n              const urlA = fullUrl.split('=')[1];\n              if (urlA) fullUrl = urlA;\n            } else if (fullUrl.includes('anaguro.yanen.org/')) {\n              fullUrl = fullUrl.replace('https://anaguro.yanen.org/', '');\n            }\n            articles.push({ title, url: fullUrl.trim() });\n          }\n        });\n      });\n\n      // Deduplicate\n      const uniqueArticles = articles.filter((article, index, self) =>\n        index === self.findIndex(a => a.url === article.url)\n      );\n      articles.splice(0, articles.length, ...uniqueArticles);\n    }\n\n    // Fallback: use page title if no articles found\n    if (articles.length === 0) {\n      const pageTitle = $('title').text().trim();\n      if (pageTitle) {\n        articles.push({ title: pageTitle, url: url });\n      }\n    }\n\n    return articles;\n  } catch (error) {\n    console.error('Error scraping articles from URL:', error);\n    throw new Error('Failed to scrape articles from URL');\n  }\n}"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AAAA;;;AAQO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAElB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,UAAU,CAAC,eAAe;wBACjC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC/B,IAAI,MAAM,UAAU;oBACtB,OAAO,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBAC9C,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,qBAAqB;QACrB,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,SAAS,OAAO,OACtD,UAAU,KAAK,SAAS,CAAC,CAAA,IAAK,EAAE,GAAG,KAAK,QAAQ,GAAG;QAGrD,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF;AAGO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAClB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,UAAU,CAAC,eAAe;wBACjC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC/B,IAAI,MAAM,UAAU;oBACtB,OAAO,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBAC9C,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,qBAAqB;QACrB,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,SAAS,OAAO,OACtD,UAAU,KAAK,SAAS,CAAC,CAAA,IAAK,EAAE,GAAG,KAAK,QAAQ,GAAG;QAGrD,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF;AAGO,eAAe,sBAAsB,QAA2B,EAAE,GAAW,EAAE,SAAkB;IACtG,IAAI;QACF,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,KAAK;YACpC,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,oCAAoC;QACpC,MAAM,YAAY;YAChB;YACA;YAAM;YAAM;YACZ;YAAU;YACV;SACD;QAED,sDAAsD;QACtD,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,UAAU,CAAC,eAAe;wBACjC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAI,CAAC,EAAE;wBAC/B,IAAI,MAAM,UAAU;oBACtB,OAAO,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBAC9C,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,8CAA8C;QAC9C,IAAI,SAAS,MAAM,KAAK,GAAG;YACzB,MAAM,mBAAmB;gBAAC;gBAAM;gBAAM;gBAAM;gBAAU;aAAiB;YACvE,iBAAiB,OAAO,CAAC,CAAA;gBACvB,EAAE,UAAU,IAAI,CAAC,CAAC,GAAG;oBACnB,MAAM,QAAQ,EAAE,MAAM,IAAI,GAAG,IAAI;oBACjC,IAAI,OAAO;wBACT,MAAM,OAAO,EAAE,MAAM,IAAI,CAAC,KAAK,IAAI,CAAC,WAAW,EAAE,MAAM,OAAO,CAAC,KAAK,IAAI,CAAC,WAAW;wBACpF,IAAI,UAAU;wBACd,IAAI,QAAQ,UAAU,CAAC,eAAe;4BACpC,MAAM,OAAO,QAAQ,KAAK,CAAC,IAAI,CAAC,EAAE;4BAClC,IAAI,MAAM,UAAU;wBACtB,OAAO,IAAI,QAAQ,QAAQ,CAAC,uBAAuB;4BACjD,UAAU,QAAQ,OAAO,CAAC,8BAA8B;wBAC1D;wBACA,SAAS,IAAI,CAAC;4BAAE;4BAAO,KAAK,QAAQ,IAAI;wBAAG;oBAC7C;gBACF;YACF;YAEA,cAAc;YACd,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,SAAS,OAAO,OACtD,UAAU,KAAK,SAAS,CAAC,CAAA,IAAK,EAAE,GAAG,KAAK,QAAQ,GAAG;YAErD,SAAS,MAAM,CAAC,GAAG,SAAS,MAAM,KAAK;QACzC;QAEA,gDAAgD;QAChD,IAAI,SAAS,MAAM,KAAK,GAAG;YACzB,MAAM,YAAY,EAAE,SAAS,IAAI,GAAG,IAAI;YACxC,IAAI,WAAW;gBACb,SAAS,IAAI,CAAC;oBAAE,OAAO;oBAAW,KAAK;gBAAI;YAC7C;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,qCAAqC;QACnD,MAAM,IAAI,MAAM;IAClB;AACF"}},
    {"offset": {"line": 466, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/database.ts"],"sourcesContent":["import Database from 'better-sqlite3';\nimport path from 'path';\n\nconsole.log('Initializing database module');\n\n// Database path\nconst dbPath = path.join(process.cwd(), 'mangaclip.db');\nconsole.log('DB path:', dbPath);\nconst db = new Database(dbPath);\nconsole.log('DB instance created');\n\n// Enable WAL mode for better concurrency\ndb.pragma('journal_mode = WAL');\n\n// Create tables\nconsole.log('Creating tables...');\ndb.exec(`\n  CREATE TABLE IF NOT EXISTS manga_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    originalTitle TEXT NOT NULL,\n    generatedTitle TEXT,\n    url TEXT NOT NULL UNIQUE,\n    targetDate TEXT,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    checked BOOLEAN DEFAULT FALSE\n  );\n\n  CREATE TABLE IF NOT EXISTS anime_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    title TEXT NOT NULL,\n    url TEXT NOT NULL UNIQUE,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP\n  );\n\n  CREATE TABLE IF NOT EXISTS article_date_tags (\n    anchor_post_id INTEGER PRIMARY KEY,\n    date TEXT NOT NULL,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP\n  );\n`);\n\n// Add post_id column if not exists\ntry {\n  db.exec(`ALTER TABLE manga_articles ADD COLUMN post_id INTEGER;`);\n  console.log('Added post_id column');\n} catch (error: any) {\n  // Column might already exist, ignore error\n  console.log('post_id column already exists or error adding:', error?.message);\n}\n\n// Add unique index for post_id if not exists\ntry {\n  db.exec(`CREATE UNIQUE INDEX IF NOT EXISTS idx_manga_articles_post_id ON manga_articles(post_id);`);\n  console.log('Created post_id index');\n} catch (error: any) {\n  console.log('Index creation error:', error?.message);\n}\n\nconsole.log('Tables created successfully');\n\n// Populate existing data with post_id if not set\ntry {\n  const rows = db.prepare('SELECT id, url FROM manga_articles WHERE post_id IS NULL').all() as { id: number; url: string }[];\n  if (rows.length > 0) {\n    const update = db.prepare('UPDATE manga_articles SET post_id = ? WHERE id = ?');\n    for (const row of rows) {\n      const match = row.url.match(/\\/post\\/(\\d+)\\//);\n      if (match) {\n        update.run(Number(match[1]), row.id);\n      }\n    }\n    console.log(`Populated post_id for ${rows.length} existing rows`);\n  }\n} catch (error: any) {\n  console.log('Error populating post_id:', error?.message);\n}\n\n// Types\nexport interface MangaArticle {\n  id: number;\n  originalTitle: string;\n  generatedTitle: string | null;\n  url: string;\n  post_id: number;\n  targetDate: string | null;\n  createdAt: string;\n  updatedAt: string;\n  checked: boolean;\n}\n\nexport interface AnimeArticle {\n  id: number;\n  title: string;\n  url: string;\n  createdAt: string;\n  updatedAt: string;\n}\n\nexport interface ArticleDateTag {\n  anchor_post_id: number;\n  date: string;\n  createdAt: string;\n}\n\nexport default db;"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,QAAQ,GAAG,CAAC;AAEZ,gBAAgB;AAChB,MAAM,SAAS,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;AACxC,QAAQ,GAAG,CAAC,YAAY;AACxB,MAAM,KAAK,IAAI,qOAAQ,CAAC;AACxB,QAAQ,GAAG,CAAC;AAEZ,yCAAyC;AACzC,GAAG,MAAM,CAAC;AAEV,gBAAgB;AAChB,QAAQ,GAAG,CAAC;AACZ,GAAG,IAAI,CAAC,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;AAyBT,CAAC;AAED,mCAAmC;AACnC,IAAI;IACF,GAAG,IAAI,CAAC,CAAC,sDAAsD,CAAC;IAChE,QAAQ,GAAG,CAAC;AACd,EAAE,OAAO,OAAY;IACnB,2CAA2C;IAC3C,QAAQ,GAAG,CAAC,kDAAkD,OAAO;AACvE;AAEA,6CAA6C;AAC7C,IAAI;IACF,GAAG,IAAI,CAAC,CAAC,wFAAwF,CAAC;IAClG,QAAQ,GAAG,CAAC;AACd,EAAE,OAAO,OAAY;IACnB,QAAQ,GAAG,CAAC,yBAAyB,OAAO;AAC9C;AAEA,QAAQ,GAAG,CAAC;AAEZ,iDAAiD;AACjD,IAAI;IACF,MAAM,OAAO,GAAG,OAAO,CAAC,4DAA4D,GAAG;IACvF,IAAI,KAAK,MAAM,GAAG,GAAG;QACnB,MAAM,SAAS,GAAG,OAAO,CAAC;QAC1B,KAAK,MAAM,OAAO,KAAM;YACtB,MAAM,QAAQ,IAAI,GAAG,CAAC,KAAK,CAAC;YAC5B,IAAI,OAAO;gBACT,OAAO,GAAG,CAAC,OAAO,KAAK,CAAC,EAAE,GAAG,IAAI,EAAE;YACrC;QACF;QACA,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,KAAK,MAAM,CAAC,cAAc,CAAC;IAClE;AACF,EAAE,OAAO,OAAY;IACnB,QAAQ,GAAG,CAAC,6BAA6B,OAAO;AAClD;uCA6Be"}},
    {"offset": {"line": 547, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/assignTargetDate.ts"],"sourcesContent":["import db from './database';\n\ninterface ScrapedArticle {\n  title: string;\n  url: string;\n}\n\nfunction extractPostId(url: string): number {\n  const match = url.match(/\\/post\\/(\\d+)\\//);\n  if (!match) throw new Error(`Invalid url: ${url}`);\n  return Number(match[1]);\n}\n\nexport function insertScrapedArticles(scraped: ScrapedArticle[]) {\n  const insert = db.prepare(`\n    INSERT OR IGNORE INTO manga_articles\n      (post_id, originalTitle, generatedTitle, url, checked, targetDate, createdAt, updatedAt)\n    VALUES (?, ?, ?, ?, 0, ?, ?, ?)\n  `);\n\n  const now = new Date().toISOString();\n  const today = new Date();\n  today.setHours(0, 0, 0, 0);\n\n  for (const article of scraped) {\n    insert.run(\n      extractPostId(article.url),\n      article.title,\n      article.title,\n      article.url,\n      today.toISOString(),\n      now,\n      now\n    );\n  }\n\n  // 件数制限: 300件を超えたら古い順に削除\n  const deleteOld = db.prepare(`\n    DELETE FROM manga_articles\n    WHERE post_id < (\n      SELECT post_id\n      FROM manga_articles\n      ORDER BY post_id DESC\n      LIMIT 1 OFFSET 299\n    )\n  `);\n  deleteOld.run();\n\n  // 孤立した日付タグを削除\n  const deleteOrphanedTags = db.prepare(`\n    DELETE FROM article_date_tags\n    WHERE anchor_post_id NOT IN (SELECT post_id FROM manga_articles)\n  `);\n  deleteOrphanedTags.run();\n}\n\n"],"names":[],"mappings":";;;;AAAA;;AAOA,SAAS,cAAc,GAAW;IAChC,MAAM,QAAQ,IAAI,KAAK,CAAC;IACxB,IAAI,CAAC,OAAO,MAAM,IAAI,MAAM,CAAC,aAAa,EAAE,KAAK;IACjD,OAAO,OAAO,KAAK,CAAC,EAAE;AACxB;AAEO,SAAS,sBAAsB,OAAyB;IAC7D,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,CAAC;;;;EAI3B,CAAC;IAED,MAAM,MAAM,IAAI,OAAO,WAAW;IAClC,MAAM,QAAQ,IAAI;IAClB,MAAM,QAAQ,CAAC,GAAG,GAAG,GAAG;IAExB,KAAK,MAAM,WAAW,QAAS;QAC7B,OAAO,GAAG,CACR,cAAc,QAAQ,GAAG,GACzB,QAAQ,KAAK,EACb,QAAQ,KAAK,EACb,QAAQ,GAAG,EACX,MAAM,WAAW,IACjB,KACA;IAEJ;IAEA,wBAAwB;IACxB,MAAM,YAAY,mKAAE,CAAC,OAAO,CAAC,CAAC;;;;;;;;EAQ9B,CAAC;IACD,UAAU,GAAG;IAEb,cAAc;IACd,MAAM,qBAAqB,mKAAE,CAAC,OAAO,CAAC,CAAC;;;EAGvC,CAAC;IACD,mBAAmB,GAAG;AACxB"}},
    {"offset": {"line": 592, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/app/api/scrape/manga/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { scrapeMangaArticles } from '@/lib/scraper';\nimport { insertScrapedArticles } from '@/lib/assignTargetDate';\nimport db, { MangaArticle } from '@/lib/database';\n\nexport async function POST() {\n  try {\n    console.log('Starting manga scrape API');\n\n    // Scrape articles\n    const scrapedArticles = await scrapeMangaArticles();\n    console.log('Scraped articles:', scrapedArticles.length);\n\n    // Get existing URLs to check duplicates\n    const existingRows = db.prepare('SELECT url FROM manga_articles').all() as { url: string }[];\n    const existingUrls = existingRows.map(row => row.url);\n    console.log('Existing URLs count:', existingUrls.length);\n    const existingUrlSet = new Set(existingUrls);\n\n    // Filter out duplicates\n    const newArticles = scrapedArticles.filter(article => !existingUrlSet.has(article.url));\n    console.log('New articles after dedup:', newArticles.length);\n\n    if (newArticles.length === 0) {\n      return NextResponse.json({\n        success: true,\n        scraped: scrapedArticles.length,\n        new: 0,\n        articles: []\n      });\n    }\n\n    // Insert new articles with assigned target dates\n    console.log('Inserting new articles');\n    insertScrapedArticles(newArticles);\n\n    console.log('Manga scrape completed successfully');\n    return NextResponse.json({\n      success: true,\n      scraped: scrapedArticles.length,\n      new: newArticles.length,\n      articles: []\n    });\n  } catch (error) {\n    console.error('Error in manga scrape:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to scrape manga articles' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function PUT(request: Request) {\n  try {\n    const body = await request.json();\n    if (body.id) {\n      const updates: string[] = [];\n      const params: any[] = [];\n      if (body.targetDate !== undefined) {\n        updates.push('targetDate = ?');\n        params.push(body.targetDate);\n      }\n      if (body.checked !== undefined) {\n        updates.push('checked = ?');\n        params.push(body.checked ? 1 : 0);\n      }\n      if (body.generatedTitle !== undefined) {\n        updates.push('generatedTitle = ?');\n        params.push(body.generatedTitle);\n      }\n      if (updates.length === 0) {\n        return NextResponse.json({ success: false, error: 'No fields to update' }, { status: 400 });\n      }\n      updates.push(\"updatedAt = datetime('now')\");\n      params.push(body.id);\n      const result = db.prepare(`UPDATE manga_articles SET ${updates.join(', ')} WHERE id = ?`).run(...params);\n      if (result.changes === 0) {\n        return NextResponse.json({ success: false, error: 'Article not found or no changes made' }, { status: 404 });\n      }\n      return NextResponse.json({ success: true });\n    } else {\n      return NextResponse.json({ success: false, error: 'Invalid request: id required' }, { status: 400 });\n    }\n  } catch (error) {\n    console.error('Error updating article:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to update article' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function DELETE(request: Request) {\n  try {\n    const body = await request.json();\n    if (body.all) {\n      // Bulk delete all manga articles and associated date tags\n      // First get all post_ids that will be deleted\n      const articlesToDelete = db.prepare('SELECT post_id FROM manga_articles').all() as { post_id: number }[];\n      const postIds = articlesToDelete.map(a => a.post_id);\n\n      // Delete associated date tags\n      if (postIds.length > 0) {\n        const placeholders = postIds.map(() => '?').join(',');\n        db.prepare(`DELETE FROM article_date_tags WHERE anchor_post_id IN (${placeholders})`).run(...postIds);\n      }\n\n      // Bulk delete all manga articles\n      const result = db.prepare('DELETE FROM manga_articles').run();\n      return NextResponse.json({ success: true, deleted: result.changes });\n    } else if (body.id) {\n      // Get post_id before marking as checked\n      const article = db.prepare('SELECT post_id FROM manga_articles WHERE id = ?').get(body.id) as { post_id: number } | undefined;\n      if (!article) {\n        return NextResponse.json({ success: false, error: 'Article not found' }, { status: 404 });\n      }\n\n      // Mark single article as checked (hide from UI)\n      const result = db.prepare(\"UPDATE manga_articles SET checked = 1, updatedAt = datetime('now') WHERE id = ?\").run(body.id);\n      if (result.changes === 0) {\n        return NextResponse.json({ success: false, error: 'Article not found' }, { status: 404 });\n      }\n\n      // Remove associated date tags\n      db.prepare('DELETE FROM article_date_tags WHERE anchor_post_id = ?').run(article.post_id);\n\n      return NextResponse.json({ success: true });\n    } else {\n      return NextResponse.json({ success: false, error: 'Invalid request' }, { status: 400 });\n    }\n  } catch (error) {\n    console.error('Error updating article:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to update article' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function GET(request: Request) {\n  try {\n    const { searchParams } = new URL(request.url);\n    const all = searchParams.get('all') === 'true';\n    if (all) {\n      const articles = db.prepare(`\n        SELECT *\n        FROM manga_articles\n        ORDER BY post_id DESC;\n      `).all() as MangaArticle[];\n      return NextResponse.json({ success: true, articles });\n    }\n\n    const limit = parseInt(searchParams.get('limit') || '15', 10);\n    if (isNaN(limit) || limit <= 0 || limit > 100) {\n      return NextResponse.json(\n        { success: false, error: 'Invalid limit parameter' },\n        { status: 400 }\n      );\n    }\n\n    const articles = db.prepare(`\n      SELECT *\n      FROM manga_articles\n      WHERE checked = 0\n      ORDER BY post_id DESC\n      LIMIT ?;\n    `).all(limit) as MangaArticle[];\n\n    return NextResponse.json({ success: true, articles });\n  } catch (error) {\n    console.error('Error fetching manga articles:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to fetch articles' },\n      { status: 500 }\n    );\n  }\n}"],"names":[],"mappings":";;;;;;;;;;AAAA;AACA;AACA;AACA;;;;;AAEO,eAAe;IACpB,IAAI;QACF,QAAQ,GAAG,CAAC;QAEZ,kBAAkB;QAClB,MAAM,kBAAkB,MAAM,IAAA,8KAAmB;QACjD,QAAQ,GAAG,CAAC,qBAAqB,gBAAgB,MAAM;QAEvD,wCAAwC;QACxC,MAAM,eAAe,mKAAE,CAAC,OAAO,CAAC,kCAAkC,GAAG;QACrE,MAAM,eAAe,aAAa,GAAG,CAAC,CAAA,MAAO,IAAI,GAAG;QACpD,QAAQ,GAAG,CAAC,wBAAwB,aAAa,MAAM;QACvD,MAAM,iBAAiB,IAAI,IAAI;QAE/B,wBAAwB;QACxB,MAAM,cAAc,gBAAgB,MAAM,CAAC,CAAA,UAAW,CAAC,eAAe,GAAG,CAAC,QAAQ,GAAG;QACrF,QAAQ,GAAG,CAAC,6BAA6B,YAAY,MAAM;QAE3D,IAAI,YAAY,MAAM,KAAK,GAAG;YAC5B,OAAO,uLAAY,CAAC,IAAI,CAAC;gBACvB,SAAS;gBACT,SAAS,gBAAgB,MAAM;gBAC/B,KAAK;gBACL,UAAU,EAAE;YACd;QACF;QAEA,iDAAiD;QACjD,QAAQ,GAAG,CAAC;QACZ,IAAA,yLAAqB,EAAC;QAEtB,QAAQ,GAAG,CAAC;QACZ,OAAO,uLAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS,gBAAgB,MAAM;YAC/B,KAAK,YAAY,MAAM;YACvB,UAAU,EAAE;QACd;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAkC,GAC3D;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe,IAAI,OAAgB;IACxC,IAAI;QACF,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,IAAI,KAAK,EAAE,EAAE;YACX,MAAM,UAAoB,EAAE;YAC5B,MAAM,SAAgB,EAAE;YACxB,IAAI,KAAK,UAAU,KAAK,WAAW;gBACjC,QAAQ,IAAI,CAAC;gBACb,OAAO,IAAI,CAAC,KAAK,UAAU;YAC7B;YACA,IAAI,KAAK,OAAO,KAAK,WAAW;gBAC9B,QAAQ,IAAI,CAAC;gBACb,OAAO,IAAI,CAAC,KAAK,OAAO,GAAG,IAAI;YACjC;YACA,IAAI,KAAK,cAAc,KAAK,WAAW;gBACrC,QAAQ,IAAI,CAAC;gBACb,OAAO,IAAI,CAAC,KAAK,cAAc;YACjC;YACA,IAAI,QAAQ,MAAM,KAAK,GAAG;gBACxB,OAAO,uLAAY,CAAC,IAAI,CAAC;oBAAE,SAAS;oBAAO,OAAO;gBAAsB,GAAG;oBAAE,QAAQ;gBAAI;YAC3F;YACA,QAAQ,IAAI,CAAC;YACb,OAAO,IAAI,CAAC,KAAK,EAAE;YACnB,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,CAAC,0BAA0B,EAAE,QAAQ,IAAI,CAAC,MAAM,aAAa,CAAC,EAAE,GAAG,IAAI;YACjG,IAAI,OAAO,OAAO,KAAK,GAAG;gBACxB,OAAO,uLAAY,CAAC,IAAI,CAAC;oBAAE,SAAS;oBAAO,OAAO;gBAAuC,GAAG;oBAAE,QAAQ;gBAAI;YAC5G;YACA,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;YAAK;QAC3C,OAAO;YACL,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAO,OAAO;YAA+B,GAAG;gBAAE,QAAQ;YAAI;QACpG;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,2BAA2B;QACzC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe,OAAO,OAAgB;IAC3C,IAAI;QACF,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,IAAI,KAAK,GAAG,EAAE;YACZ,0DAA0D;YAC1D,8CAA8C;YAC9C,MAAM,mBAAmB,mKAAE,CAAC,OAAO,CAAC,sCAAsC,GAAG;YAC7E,MAAM,UAAU,iBAAiB,GAAG,CAAC,CAAA,IAAK,EAAE,OAAO;YAEnD,8BAA8B;YAC9B,IAAI,QAAQ,MAAM,GAAG,GAAG;gBACtB,MAAM,eAAe,QAAQ,GAAG,CAAC,IAAM,KAAK,IAAI,CAAC;gBACjD,mKAAE,CAAC,OAAO,CAAC,CAAC,uDAAuD,EAAE,aAAa,CAAC,CAAC,EAAE,GAAG,IAAI;YAC/F;YAEA,iCAAiC;YACjC,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,8BAA8B,GAAG;YAC3D,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAM,SAAS,OAAO,OAAO;YAAC;QACpE,OAAO,IAAI,KAAK,EAAE,EAAE;YAClB,wCAAwC;YACxC,MAAM,UAAU,mKAAE,CAAC,OAAO,CAAC,mDAAmD,GAAG,CAAC,KAAK,EAAE;YACzF,IAAI,CAAC,SAAS;gBACZ,OAAO,uLAAY,CAAC,IAAI,CAAC;oBAAE,SAAS;oBAAO,OAAO;gBAAoB,GAAG;oBAAE,QAAQ;gBAAI;YACzF;YAEA,gDAAgD;YAChD,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,mFAAmF,GAAG,CAAC,KAAK,EAAE;YACxH,IAAI,OAAO,OAAO,KAAK,GAAG;gBACxB,OAAO,uLAAY,CAAC,IAAI,CAAC;oBAAE,SAAS;oBAAO,OAAO;gBAAoB,GAAG;oBAAE,QAAQ;gBAAI;YACzF;YAEA,8BAA8B;YAC9B,mKAAE,CAAC,OAAO,CAAC,0DAA0D,GAAG,CAAC,QAAQ,OAAO;YAExF,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;YAAK;QAC3C,OAAO;YACL,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAO,OAAO;YAAkB,GAAG;gBAAE,QAAQ;YAAI;QACvF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,2BAA2B;QACzC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe,IAAI,OAAgB;IACxC,IAAI;QACF,MAAM,EAAE,YAAY,EAAE,GAAG,IAAI,IAAI,QAAQ,GAAG;QAC5C,MAAM,MAAM,aAAa,GAAG,CAAC,WAAW;QACxC,IAAI,KAAK;YACP,MAAM,WAAW,mKAAE,CAAC,OAAO,CAAC,CAAC;;;;MAI7B,CAAC,EAAE,GAAG;YACN,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAM;YAAS;QACrD;QAEA,MAAM,QAAQ,SAAS,aAAa,GAAG,CAAC,YAAY,MAAM;QAC1D,IAAI,MAAM,UAAU,SAAS,KAAK,QAAQ,KAAK;YAC7C,OAAO,uLAAY,CAAC,IAAI,CACtB;gBAAE,SAAS;gBAAO,OAAO;YAA0B,GACnD;gBAAE,QAAQ;YAAI;QAElB;QAEA,MAAM,WAAW,mKAAE,CAAC,OAAO,CAAC,CAAC;;;;;;IAM7B,CAAC,EAAE,GAAG,CAAC;QAEP,OAAO,uLAAY,CAAC,IAAI,CAAC;YAAE,SAAS;YAAM;QAAS;IACrD,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}