{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 262, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/scraper.ts"],"sourcesContent":["import axios from 'axios';\nimport * as cheerio from 'cheerio';\n\nexport interface ScrapedArticle {\n  title: string;\n  url: string;\n}\n\n// Manga summary news\nexport async function scrapeMangaArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?key=%e6%bc%ab%e7%94%bb%e3%81%be%e3%81%a8%e3%82%81%e9%80%9f%e5%a0%b1';\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    return articles;\n  } catch (error) {\n    console.error('Error scraping manga articles:', error);\n    throw new Error('Failed to scrape manga articles');\n  }\n}\n\n// Anime summary\nexport async function scrapeAnimeArticles(): Promise<ScrapedArticle[]> {\n  try {\n    const targetUrl = 'https://anaguro.yanen.org/search.cgi?c_10=1&c_11=1&c_15=1&c_16=1&c_17=1&c_20=1&c_24=1&c_30=1&c_31=1&c_40=1&c_41=1&c_45=1&c_51=1&c_60=1&c_61=1&c_63=1&c_70=1&c_95=1&c_99=1&type=month&key=%E3%82%A2%E3%83%8B%E3%83%A1%E3%81%BE%E3%81%A8%E3%82%81&btn=%E3%81%8A&chkb=1';\n    const response = await axios.get(targetUrl, {\n      headers: {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n      }\n    });\n\n    const $ = cheerio.load(response.data);\n    const articles: ScrapedArticle[] = [];\n\n    // Based on Python code: table.table01 > tr with hr > td.title > a.title\n    const hrPosts: any[] = [];\n    $('table.table01 tr').each((_, row) => {\n      if ($(row).find('hr').length > 0) {\n        hrPosts.push(row);\n      }\n    });\n\n    hrPosts.forEach((titles) => {\n      const titleElem = $(titles).find('td.title');\n      const aTag = $(titles).find('a.title');\n\n      if (titleElem.length > 0 && aTag.length > 0) {\n        const title = titleElem.text().trim();\n        const href = aTag.attr('href');\n        if (title && href) {\n          let fullUrl = href;\n          if (href.includes('anaguro.yanen.org/')) {\n            fullUrl = href.replace('https://anaguro.yanen.org/', '');\n          }\n          articles.push({ title, url: fullUrl.trim() });\n        }\n      }\n    });\n\n    return articles;\n  } catch (error) {\n    console.error('Error scraping anime articles:', error);\n    throw new Error('Failed to scrape anime articles');\n  }\n}"],"names":[],"mappings":";;;;;;AAAA;AACA;AAAA;;;AAQO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAClB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBACvC,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF;AAGO,eAAe;IACpB,IAAI;QACF,MAAM,YAAY;QAClB,MAAM,WAAW,MAAM,yLAAK,CAAC,GAAG,CAAC,WAAW;YAC1C,SAAS;gBACP,cAAc;YAChB;QACF;QAEA,MAAM,IAAI,wMAAY,CAAC,SAAS,IAAI;QACpC,MAAM,WAA6B,EAAE;QAErC,wEAAwE;QACxE,MAAM,UAAiB,EAAE;QACzB,EAAE,oBAAoB,IAAI,CAAC,CAAC,GAAG;YAC7B,IAAI,EAAE,KAAK,IAAI,CAAC,MAAM,MAAM,GAAG,GAAG;gBAChC,QAAQ,IAAI,CAAC;YACf;QACF;QAEA,QAAQ,OAAO,CAAC,CAAC;YACf,MAAM,YAAY,EAAE,QAAQ,IAAI,CAAC;YACjC,MAAM,OAAO,EAAE,QAAQ,IAAI,CAAC;YAE5B,IAAI,UAAU,MAAM,GAAG,KAAK,KAAK,MAAM,GAAG,GAAG;gBAC3C,MAAM,QAAQ,UAAU,IAAI,GAAG,IAAI;gBACnC,MAAM,OAAO,KAAK,IAAI,CAAC;gBACvB,IAAI,SAAS,MAAM;oBACjB,IAAI,UAAU;oBACd,IAAI,KAAK,QAAQ,CAAC,uBAAuB;wBACvC,UAAU,KAAK,OAAO,CAAC,8BAA8B;oBACvD;oBACA,SAAS,IAAI,CAAC;wBAAE;wBAAO,KAAK,QAAQ,IAAI;oBAAG;gBAC7C;YACF;QACF;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,MAAM,IAAI,MAAM;IAClB;AACF"}},
    {"offset": {"line": 359, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/database.ts"],"sourcesContent":["import Database from 'better-sqlite3';\nimport path from 'path';\n\nconsole.log('Initializing database module');\n\n// Database path\nconst dbPath = path.join(process.cwd(), 'mangaclip.db');\nconsole.log('DB path:', dbPath);\nconst db = new Database(dbPath);\nconsole.log('DB instance created');\n\n// Enable WAL mode for better concurrency\ndb.pragma('journal_mode = WAL');\n\n// Create tables\nconsole.log('Creating tables...');\ndb.exec(`\n  CREATE TABLE IF NOT EXISTS manga_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    originalTitle TEXT NOT NULL,\n    generatedTitle TEXT,\n    url TEXT NOT NULL UNIQUE,\n    targetDate TEXT,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    checked BOOLEAN DEFAULT FALSE\n  );\n\n  CREATE TABLE IF NOT EXISTS anime_articles (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    title TEXT NOT NULL,\n    url TEXT NOT NULL UNIQUE,\n    createdAt DATETIME DEFAULT CURRENT_TIMESTAMP,\n    updatedAt DATETIME DEFAULT CURRENT_TIMESTAMP\n  );\n`);\nconsole.log('Tables created successfully');\n\n// Types\nexport interface MangaArticle {\n  id: number;\n  originalTitle: string;\n  generatedTitle: string | null;\n  url: string;\n  targetDate: string | null;\n  createdAt: string;\n  updatedAt: string;\n  checked: boolean;\n}\n\nexport interface AnimeArticle {\n  id: number;\n  title: string;\n  url: string;\n  createdAt: string;\n  updatedAt: string;\n}\n\nexport default db;"],"names":[],"mappings":";;;;AAAA;AACA;;;AAEA,QAAQ,GAAG,CAAC;AAEZ,gBAAgB;AAChB,MAAM,SAAS,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI;AACxC,QAAQ,GAAG,CAAC,YAAY;AACxB,MAAM,KAAK,IAAI,qOAAQ,CAAC;AACxB,QAAQ,GAAG,CAAC;AAEZ,yCAAyC;AACzC,GAAG,MAAM,CAAC;AAEV,gBAAgB;AAChB,QAAQ,GAAG,CAAC;AACZ,GAAG,IAAI,CAAC,CAAC;;;;;;;;;;;;;;;;;;;AAmBT,CAAC;AACD,QAAQ,GAAG,CAAC;uCAsBG"}},
    {"offset": {"line": 403, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/lib/assignTargetDate.ts"],"sourcesContent":["import { MangaArticle } from './database';\nimport db from './database';\n\nexport function assignTargetDates(newArticles: Omit<MangaArticle, 'id' | 'createdAt' | 'updatedAt'>[]): Omit<MangaArticle, 'id' | 'createdAt' | 'updatedAt'>[] {\n  console.log(`Assigning target dates for ${newArticles.length} articles`);\n\n  // Get the latest targetDate from database\n  const row = db.prepare('SELECT targetDate FROM manga_articles WHERE targetDate IS NOT NULL ORDER BY targetDate DESC LIMIT 1').get() as { targetDate: string } | undefined;\n  const latestTargetDate = row?.targetDate || null;\n  console.log('Latest targetDate from database:', latestTargetDate);\n\n  let latestDate: Date;\n\n  if (latestTargetDate) {\n    latestDate = new Date(latestTargetDate);\n    console.log('Using latest date from storage:', latestDate.toISOString());\n  } else {\n    // If no articles, start from today 21:00\n    latestDate = new Date();\n    latestDate.setHours(21, 0, 0, 0);\n    console.log('No articles in storage, starting from today 21:00:', latestDate.toISOString());\n  }\n\n  // Assign targetDates in reverse order (newest first)\n  const assignedArticles = newArticles.map(article => {\n    let hour = latestDate.getHours() - 1;\n\n    if (hour < 7) {\n      // Move to previous day 21:00\n      const prevDay = new Date(latestDate);\n      prevDay.setDate(prevDay.getDate() - 1);\n      prevDay.setHours(21, 0, 0, 0);\n      latestDate = prevDay;\n      hour = 21;\n    }\n\n    const targetDate = new Date(\n      latestDate.getFullYear(),\n      latestDate.getMonth(),\n      latestDate.getDate(),\n      hour, 0, 0, 0\n    );\n\n    latestDate = targetDate;\n\n    return {\n      ...article,\n      targetDate: targetDate.toISOString()\n    };\n  });\n\n  return assignedArticles;\n}"],"names":[],"mappings":";;;;AACA;;AAEO,SAAS,kBAAkB,WAAmE;IACnG,QAAQ,GAAG,CAAC,CAAC,2BAA2B,EAAE,YAAY,MAAM,CAAC,SAAS,CAAC;IAEvE,0CAA0C;IAC1C,MAAM,MAAM,mKAAE,CAAC,OAAO,CAAC,uGAAuG,GAAG;IACjI,MAAM,mBAAmB,KAAK,cAAc;IAC5C,QAAQ,GAAG,CAAC,oCAAoC;IAEhD,IAAI;IAEJ,IAAI,kBAAkB;QACpB,aAAa,IAAI,KAAK;QACtB,QAAQ,GAAG,CAAC,mCAAmC,WAAW,WAAW;IACvE,OAAO;QACL,yCAAyC;QACzC,aAAa,IAAI;QACjB,WAAW,QAAQ,CAAC,IAAI,GAAG,GAAG;QAC9B,QAAQ,GAAG,CAAC,sDAAsD,WAAW,WAAW;IAC1F;IAEA,qDAAqD;IACrD,MAAM,mBAAmB,YAAY,GAAG,CAAC,CAAA;QACvC,IAAI,OAAO,WAAW,QAAQ,KAAK;QAEnC,IAAI,OAAO,GAAG;YACZ,6BAA6B;YAC7B,MAAM,UAAU,IAAI,KAAK;YACzB,QAAQ,OAAO,CAAC,QAAQ,OAAO,KAAK;YACpC,QAAQ,QAAQ,CAAC,IAAI,GAAG,GAAG;YAC3B,aAAa;YACb,OAAO;QACT;QAEA,MAAM,aAAa,IAAI,KACrB,WAAW,WAAW,IACtB,WAAW,QAAQ,IACnB,WAAW,OAAO,IAClB,MAAM,GAAG,GAAG;QAGd,aAAa;QAEb,OAAO;YACL,GAAG,OAAO;YACV,YAAY,WAAW,WAAW;QACpC;IACF;IAEA,OAAO;AACT"}},
    {"offset": {"line": 449, "column": 0}, "map": {"version":3,"sources":["file:///Users/masaki/Desktop/OriginalApp/MangaClip/app/api/scrape/manga/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\nimport { scrapeMangaArticles } from '@/lib/scraper';\nimport { assignTargetDates } from '@/lib/assignTargetDate';\nimport db, { MangaArticle } from '@/lib/database';\n\nexport async function POST() {\n  try {\n    console.log('Starting manga scrape API');\n\n    // Scrape articles\n    const scrapedArticles = await scrapeMangaArticles();\n    console.log('Scraped articles:', scrapedArticles.length);\n\n    // Get existing URLs to check duplicates\n    const existingRows = db.prepare('SELECT url FROM manga_articles').all() as { url: string }[];\n    const existingUrls = existingRows.map(row => row.url);\n    console.log('Existing URLs count:', existingUrls.length);\n    const existingUrlSet = new Set(existingUrls);\n\n    // Filter out duplicates\n    const newArticles = scrapedArticles.filter(article => !existingUrlSet.has(article.url));\n    console.log('New articles after dedup:', newArticles.length);\n\n    if (newArticles.length === 0) {\n      return NextResponse.json({\n        success: true,\n        scraped: scrapedArticles.length,\n        new: 0,\n        articles: []\n      });\n    }\n\n    // Assign target dates\n    console.log('Assigning target dates');\n    const articlesWithTargetDate = assignTargetDates(newArticles.map(article => ({\n      originalTitle: article.title,\n      generatedTitle: null,\n      url: article.url,\n      targetDate: '', // will be assigned\n      checked: false\n    })));\n    console.log('Target dates assigned, count:', articlesWithTargetDate.length);\n\n    // Insert new articles\n    const insertStmt = db.prepare(`\n      INSERT INTO manga_articles (originalTitle, generatedTitle, url, targetDate, checked)\n      VALUES (?, ?, ?, ?, ?)\n    `);\n    const insertedArticles: MangaArticle[] = [];\n\n    for (const article of articlesWithTargetDate) {\n      console.log('Inserting article:', article.originalTitle.substring(0, 50));\n      const result = insertStmt.run(\n        article.originalTitle,\n        article.generatedTitle,\n        article.url,\n        article.targetDate,\n        article.checked ? 1 : 0\n      );\n      const insertedArticle = db.prepare('SELECT * FROM manga_articles WHERE id = ?').get(result.lastInsertRowid) as MangaArticle;\n      insertedArticles.push(insertedArticle);\n    }\n\n    console.log('Manga scrape completed successfully');\n    return NextResponse.json({\n      success: true,\n      scraped: scrapedArticles.length,\n      new: newArticles.length,\n      articles: insertedArticles\n    });\n  } catch (error) {\n    console.error('Error in manga scrape:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to scrape manga articles' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function DELETE(request: Request) {\n  try {\n    const body = await request.json();\n    if (body.all) {\n      // Bulk delete all manga articles\n      const result = db.prepare('DELETE FROM manga_articles').run();\n      return NextResponse.json({ success: true, deleted: result.changes });\n    } else if (body.id) {\n      // Delete single article\n      const result = db.prepare('DELETE FROM manga_articles WHERE id = ?').run(body.id);\n      if (result.changes === 0) {\n        return NextResponse.json({ success: false, error: 'Article not found' }, { status: 404 });\n      }\n      return NextResponse.json({ success: true });\n    } else {\n      return NextResponse.json({ success: false, error: 'Invalid request' }, { status: 400 });\n    }\n  } catch (error) {\n    console.error('Error deleting article:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to delete article' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function GET() {\n  try {\n    const articles = db.prepare(`\n      SELECT * FROM manga_articles\n      ORDER BY targetDate DESC, targetDate ASC\n    `).all() as MangaArticle[];\n    console.log('Articles count:', articles.length);\n    console.log('First article targetDate:', articles[0]?.targetDate);\n\n    return NextResponse.json({ success: true, articles });\n  } catch (error) {\n    console.error('Error fetching manga articles:', error);\n    return NextResponse.json(\n      { success: false, error: 'Failed to fetch articles' },\n      { status: 500 }\n    );\n  }\n}"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;AACA;;;;;AAEO,eAAe;IACpB,IAAI;QACF,QAAQ,GAAG,CAAC;QAEZ,kBAAkB;QAClB,MAAM,kBAAkB,MAAM,IAAA,8KAAmB;QACjD,QAAQ,GAAG,CAAC,qBAAqB,gBAAgB,MAAM;QAEvD,wCAAwC;QACxC,MAAM,eAAe,mKAAE,CAAC,OAAO,CAAC,kCAAkC,GAAG;QACrE,MAAM,eAAe,aAAa,GAAG,CAAC,CAAA,MAAO,IAAI,GAAG;QACpD,QAAQ,GAAG,CAAC,wBAAwB,aAAa,MAAM;QACvD,MAAM,iBAAiB,IAAI,IAAI;QAE/B,wBAAwB;QACxB,MAAM,cAAc,gBAAgB,MAAM,CAAC,CAAA,UAAW,CAAC,eAAe,GAAG,CAAC,QAAQ,GAAG;QACrF,QAAQ,GAAG,CAAC,6BAA6B,YAAY,MAAM;QAE3D,IAAI,YAAY,MAAM,KAAK,GAAG;YAC5B,OAAO,uLAAY,CAAC,IAAI,CAAC;gBACvB,SAAS;gBACT,SAAS,gBAAgB,MAAM;gBAC/B,KAAK;gBACL,UAAU,EAAE;YACd;QACF;QAEA,sBAAsB;QACtB,QAAQ,GAAG,CAAC;QACZ,MAAM,yBAAyB,IAAA,qLAAiB,EAAC,YAAY,GAAG,CAAC,CAAA,UAAW,CAAC;gBAC3E,eAAe,QAAQ,KAAK;gBAC5B,gBAAgB;gBAChB,KAAK,QAAQ,GAAG;gBAChB,YAAY;gBACZ,SAAS;YACX,CAAC;QACD,QAAQ,GAAG,CAAC,iCAAiC,uBAAuB,MAAM;QAE1E,sBAAsB;QACtB,MAAM,aAAa,mKAAE,CAAC,OAAO,CAAC,CAAC;;;IAG/B,CAAC;QACD,MAAM,mBAAmC,EAAE;QAE3C,KAAK,MAAM,WAAW,uBAAwB;YAC5C,QAAQ,GAAG,CAAC,sBAAsB,QAAQ,aAAa,CAAC,SAAS,CAAC,GAAG;YACrE,MAAM,SAAS,WAAW,GAAG,CAC3B,QAAQ,aAAa,EACrB,QAAQ,cAAc,EACtB,QAAQ,GAAG,EACX,QAAQ,UAAU,EAClB,QAAQ,OAAO,GAAG,IAAI;YAExB,MAAM,kBAAkB,mKAAE,CAAC,OAAO,CAAC,6CAA6C,GAAG,CAAC,OAAO,eAAe;YAC1G,iBAAiB,IAAI,CAAC;QACxB;QAEA,QAAQ,GAAG,CAAC;QACZ,OAAO,uLAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,SAAS,gBAAgB,MAAM;YAC/B,KAAK,YAAY,MAAM;YACvB,UAAU;QACZ;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0BAA0B;QACxC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAAkC,GAC3D;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe,OAAO,OAAgB;IAC3C,IAAI;QACF,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,IAAI,KAAK,GAAG,EAAE;YACZ,iCAAiC;YACjC,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,8BAA8B,GAAG;YAC3D,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAM,SAAS,OAAO,OAAO;YAAC;QACpE,OAAO,IAAI,KAAK,EAAE,EAAE;YAClB,wBAAwB;YACxB,MAAM,SAAS,mKAAE,CAAC,OAAO,CAAC,2CAA2C,GAAG,CAAC,KAAK,EAAE;YAChF,IAAI,OAAO,OAAO,KAAK,GAAG;gBACxB,OAAO,uLAAY,CAAC,IAAI,CAAC;oBAAE,SAAS;oBAAO,OAAO;gBAAoB,GAAG;oBAAE,QAAQ;gBAAI;YACzF;YACA,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;YAAK;QAC3C,OAAO;YACL,OAAO,uLAAY,CAAC,IAAI,CAAC;gBAAE,SAAS;gBAAO,OAAO;YAAkB,GAAG;gBAAE,QAAQ;YAAI;QACvF;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,2BAA2B;QACzC,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe;IACpB,IAAI;QACF,MAAM,WAAW,mKAAE,CAAC,OAAO,CAAC,CAAC;;;IAG7B,CAAC,EAAE,GAAG;QACN,QAAQ,GAAG,CAAC,mBAAmB,SAAS,MAAM;QAC9C,QAAQ,GAAG,CAAC,6BAA6B,QAAQ,CAAC,EAAE,EAAE;QAEtD,OAAO,uLAAY,CAAC,IAAI,CAAC;YAAE,SAAS;YAAM;QAAS;IACrD,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,kCAAkC;QAChD,OAAO,uLAAY,CAAC,IAAI,CACtB;YAAE,SAAS;YAAO,OAAO;QAA2B,GACpD;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}